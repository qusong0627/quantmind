#!/usr/bin/env python3
"""
LLMé…ç½®åŠ è½½å™¨
è´Ÿè´£ä»ç¯å¢ƒå˜é‡ã€é…ç½®æ–‡ä»¶ç­‰å¤šç§æ¥æºåŠ è½½LLM APIé…ç½®
"""

import os
import yaml
import json
from pathlib import Path
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv

from .llm_api_config import LLMAPIConfig, LLMAPIManager, LLMProvider


class LLMConfigLoader:
    """LLMé…ç½®åŠ è½½å™¨"""
    
    def __init__(self, config_dir: Optional[str] = None):
        self.config_dir = Path(config_dir) if config_dir else Path(__file__).parent
        self.project_root = self.config_dir.parent
        self.api_manager = LLMAPIManager()
        
        # åŠ è½½ç¯å¢ƒå˜é‡
        self._load_env_files()
    
    def _load_env_files(self):
        """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
        env_files = [
            self.config_dir / '.env.llm',
            self.config_dir / '.env',
            self.project_root / '.env.llm',
            self.project_root / '.env'
        ]
        
        for env_file in env_files:
            if env_file.exists():
                load_dotenv(env_file)
                print(f"å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
    
    def load_from_yaml(self, yaml_file: str) -> Dict[str, Any]:
        """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
        yaml_path = self.config_dir / yaml_file
        if not yaml_path.exists():
            yaml_path = self.project_root / "backend" / "ai-strategy" / yaml_file
        
        if yaml_path.exists():
            with open(yaml_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return {}
    
    def load_from_json(self, json_file: str) -> Dict[str, Any]:
        """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®"""
        json_path = self.config_dir / json_file
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def create_config_from_env(self, provider: str) -> Optional[LLMAPIConfig]:
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        provider_upper = provider.upper()
        api_key = os.getenv(f'{provider_upper}_API_KEY')
        
        if not api_key:
            return None
        
        # é¢„å®šä¹‰çš„é…ç½®æ˜ å°„
        config_mapping = {
            'qwen': {
                'api_url': 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
                'model': 'qwen-plus',
                'description': 'é˜¿é‡Œäº‘é€šä¹‰åƒé—®å¤§æ¨¡å‹',
                'tags': ['ä¸­æ–‡ä¼˜åŒ–', 'æ¨è']
            },
            'gemini': {
                'api_url': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent',
                'model': 'gemini-2.0-flash',
                'description': 'Google Geminiå¤šæ¨¡æ€æ¨¡å‹',
                'tags': ['å¤šæ¨¡æ€', 'æ–°é”']
            },
            'openai': {
                'api_url': 'https://api.openai.com/v1/chat/completions',
                'model': 'gpt-4',
                'description': 'OpenAI GPT-4æ¨¡å‹',
                'tags': ['é€šç”¨', 'å¤‡é€‰']
            },
            'claude': {
                'api_url': 'https://api.anthropic.com/v1/messages',
                'model': 'claude-3-sonnet-20240229',
                'description': 'Anthropic Claudeæ¨¡å‹',
                'tags': ['å®‰å…¨', 'é¢„ç•™']
            },
            'baidu': {
                'api_url': 'https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions',
                'model': 'ernie-bot-turbo',
                'description': 'ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¨¡å‹',
                'tags': ['ä¸­æ–‡', 'æœ¬åœŸ']
            },
            'zhipu': {
                'api_url': 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
                'model': 'glm-4',
                'description': 'æ™ºè°±AI GLM-4æ¨¡å‹',
                'tags': ['ä¸­æ–‡', 'é¢„ç•™']
            }
        }
        
        if provider not in config_mapping:
            return None
        
        base_config = config_mapping[provider]
        
        # ä»ç¯å¢ƒå˜é‡è·å–è‡ªå®šä¹‰é…ç½®
        api_url = os.getenv(f'{provider_upper}_API_URL', base_config['api_url'])
        model = os.getenv(f'{provider_upper}_MODEL', base_config['model'])
        enabled = os.getenv(f'{provider_upper}_ENABLED', 'true').lower() == 'true'
        priority = int(os.getenv(f'{provider_upper}_PRIORITY', '1'))
        max_tokens = int(os.getenv(f'{provider_upper}_MAX_TOKENS', '2000'))
        temperature = float(os.getenv(f'{provider_upper}_TEMPERATURE', '0.7'))
        timeout = int(os.getenv(f'{provider_upper}_TIMEOUT', '30'))
        
        return LLMAPIConfig(
            provider=provider,
            api_key=api_key,
            api_url=api_url,
            model=model,
            enabled=enabled,
            priority=priority,
            max_tokens=max_tokens,
            temperature=temperature,
            timeout=timeout,
            description=base_config['description'],
            tags=base_config['tags']
        )
    
    def load_all_configs(self) -> LLMAPIManager:
        """åŠ è½½æ‰€æœ‰é…ç½®"""
        # 1. ä»ç¯å¢ƒå˜é‡åŠ è½½
        for provider in LLMProvider:
            config = self.create_config_from_env(provider.value)
            if config:
                self.api_manager.add_config(config)
        
        # 2. ä»YAMLé…ç½®æ–‡ä»¶åŠ è½½ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        yaml_config = self.load_from_yaml('config.yaml')
        if 'llm_providers' in yaml_config:
            self._merge_yaml_config(yaml_config['llm_providers'])
        
        # 3. åº”ç”¨å…¨å±€é…ç½®
        self._apply_global_config()
        
        return self.api_manager
    
    def _merge_yaml_config(self, yaml_providers: Dict[str, Any]):
        """åˆå¹¶YAMLé…ç½®"""
        for provider_name, provider_config in yaml_providers.items():
            existing_config = self.api_manager.get_config(provider_name)
            if existing_config:
                # æ›´æ–°ç°æœ‰é…ç½®
                if 'enabled' in provider_config:
                    existing_config.enabled = provider_config['enabled']
                if 'priority' in provider_config:
                    existing_config.priority = provider_config['priority']
                if 'model' in provider_config:
                    existing_config.model = provider_config['model']
                if 'api_url' in provider_config:
                    existing_config.api_url = provider_config['api_url']
                if 'description' in provider_config:
                    existing_config.description = provider_config['description']
    
    def _apply_global_config(self):
        """åº”ç”¨å…¨å±€é…ç½®"""
        # é»˜è®¤æä¾›å•†
        default_provider = os.getenv('DEFAULT_LLM_PROVIDER', 'qwen')
        if default_provider in self.api_manager._configs:
            self.api_manager._configs[default_provider].priority = 1
        
        # è‡ªåŠ¨å›é€€
        enable_fallback = os.getenv('ENABLE_AUTO_FALLBACK', 'true').lower() == 'true'
        if enable_fallback:
            # ä¸ºå¯ç”¨çš„é…ç½®è®¾ç½®é€’å¢ä¼˜å…ˆçº§
            enabled_configs = list(self.api_manager.get_enabled_configs().values())
            enabled_configs.sort(key=lambda x: x.priority)
            for i, config in enumerate(enabled_configs):
                config.priority = i + 1
    
    def save_config_to_yaml(self, output_file: str = 'llm_config_generated.yaml'):
        """å°†å½“å‰é…ç½®ä¿å­˜åˆ°YAMLæ–‡ä»¶"""
        config_data = {
            'llm_providers': {}
        }
        
        for provider, config in self.api_manager.get_all_configs().items():
            config_data['llm_providers'][provider] = {
                'enabled': config.enabled,
                'priority': config.priority,
                'api_url': config.api_url,
                'model': config.model,
                'max_tokens': config.max_tokens,
                'temperature': config.temperature,
                'timeout': config.timeout,
                'description': config.description,
                'tags': config.tags,
                'rate_limit': config.rate_limit
            }
        
        output_path = self.config_dir / output_file
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_data, f, default_flow_style=False, allow_unicode=True, indent=2)
        
        print(f"é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
    
    def validate_all_configs(self) -> Dict[str, bool]:
        """éªŒè¯æ‰€æœ‰é…ç½®"""
        results = {}
        for provider in self.api_manager.get_all_configs().keys():
            results[provider] = self.api_manager.validate_config(provider)
        return results
    
    def get_config_status(self) -> Dict[str, Dict[str, Any]]:
        """è·å–é…ç½®çŠ¶æ€æŠ¥å‘Š"""
        status = {}
        validation_results = self.validate_all_configs()
        
        for provider, config in self.api_manager.get_all_configs().items():
            status[provider] = {
                'enabled': config.enabled,
                'valid': validation_results[provider],
                'has_api_key': bool(config.api_key),
                'priority': config.priority,
                'model': config.model,
                'description': config.description,
                'tags': config.tags
            }
        
        return status


def create_sample_env_file():
    """åˆ›å»ºç¤ºä¾‹ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    config_dir = Path(__file__).parent
    env_file = config_dir / '.env.llm'
    
    if env_file.exists():
        print(f"ç¯å¢ƒå˜é‡æ–‡ä»¶å·²å­˜åœ¨: {env_file}")
        return
    
    # å¤åˆ¶æ¨¡æ¿æ–‡ä»¶
    template_file = config_dir / '.env.llm.template'
    if template_file.exists():
        import shutil
        shutil.copy(template_file, env_file)
        print(f"å·²åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
        print("è¯·ç¼–è¾‘æ­¤æ–‡ä»¶å¹¶å¡«å…¥æ‚¨çš„APIå¯†é’¥")
    else:
        print(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_file}")


if __name__ == "__main__":
    print("=== LLMé…ç½®åŠ è½½å™¨æµ‹è¯• ===")
    
    # åˆ›å»ºé…ç½®åŠ è½½å™¨
    loader = LLMConfigLoader()
    
    # åŠ è½½æ‰€æœ‰é…ç½®
    api_manager = loader.load_all_configs()
    
    # æ˜¾ç¤ºé…ç½®çŠ¶æ€
    status = loader.get_config_status()
    print("\né…ç½®çŠ¶æ€æŠ¥å‘Š:")
    print("-" * 60)
    for provider, info in status.items():
        status_icon = "âœ…" if info['valid'] and info['enabled'] else "âŒ"
        key_status = "ğŸ”‘" if info['has_api_key'] else "ğŸš«"
        print(f"{status_icon} {key_status} {provider.upper()}:")
        print(f"   æ¨¡å‹: {info['model']}")
        print(f"   æè¿°: {info['description']}")
        print(f"   ä¼˜å…ˆçº§: {info['priority']}")
        print(f"   æ ‡ç­¾: {', '.join(info['tags'])}")
        print(f"   çŠ¶æ€: {'å¯ç”¨' if info['enabled'] else 'ç¦ç”¨'} | {'æœ‰æ•ˆ' if info['valid'] else 'æ— æ•ˆ'}")
        print()
    
    # æ˜¾ç¤ºå¯ç”¨çš„é…ç½®
    enabled_configs = api_manager.get_enabled_configs()
    print(f"å¯ç”¨çš„æ¨¡å‹æ•°é‡: {len(enabled_configs)}")
    
    if enabled_configs:
        print("\næŒ‰ä¼˜å…ˆçº§æ’åºçš„å¯ç”¨æ¨¡å‹:")
        sorted_configs = api_manager.get_configs_by_priority()
        for i, config in enumerate(sorted_configs, 1):
            print(f"{i}. {config.provider} ({config.model}) - ä¼˜å…ˆçº§: {config.priority}")
    
    # ä¿å­˜é…ç½®åˆ°YAML
    loader.save_config_to_yaml()
    
    print("\nğŸ’¡ æç¤º:")
    print("1. è¯·ç¡®ä¿åœ¨ .env.llm æ–‡ä»¶ä¸­é…ç½®äº†æ­£ç¡®çš„APIå¯†é’¥")
    print("2. ä½¿ç”¨ python -c 'from config.llm_config_loader import create_sample_env_file; create_sample_env_file()' åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶")
    print("3. é‡å¯åº”ç”¨ç¨‹åºä»¥åŠ è½½æ–°é…ç½®")