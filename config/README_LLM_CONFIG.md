# LLM APIé…ç½®ç®¡ç†ç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºQuantMindç³»ç»Ÿè®¾è®¡çš„å¤§è¯­è¨€æ¨¡å‹APIé…ç½®ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒå¤šæ¨¡å‹APIçš„ç»Ÿä¸€ç®¡ç†ã€åŠ¨æ€åˆ‡æ¢å’Œä¼˜å…ˆçº§æ§åˆ¶ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- **å¤šæä¾›å•†æ”¯æŒ**: æ”¯æŒQwenã€Geminiã€OpenAIã€Claudeã€ç™¾åº¦ã€æ™ºè°±ç­‰ä¸»æµLLMæä¾›å•†
- **ç»Ÿä¸€æ¥å£**: æä¾›ç»Ÿä¸€çš„APIå¯†é’¥è·å–å’Œè®¾ç½®æ¥å£
- **ä¼˜å…ˆçº§ç®¡ç†**: æ”¯æŒæä¾›å•†ä¼˜å…ˆçº§è®¾ç½®å’Œè‡ªåŠ¨åˆ‡æ¢
- **é…ç½®éªŒè¯**: è‡ªåŠ¨éªŒè¯APIå¯†é’¥å’Œè¿æ¥çŠ¶æ€
- **ç¯å¢ƒå˜é‡é›†æˆ**: æ”¯æŒä»ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶åŠ è½½è®¾ç½®
- **å‘åå…¼å®¹**: ä¸ç°æœ‰APIé…ç½®ç³»ç»Ÿå®Œå…¨å…¼å®¹
- **å‘½ä»¤è¡Œå·¥å…·**: æä¾›CLIå·¥å…·è¿›è¡Œé…ç½®ç®¡ç†

## ğŸ“ æ–‡ä»¶ç»“æ„

```
config/
â”œâ”€â”€ llm_api_config.py          # LLM APIé…ç½®æ•°æ®ç»“æ„å’Œç®¡ç†å™¨
â”œâ”€â”€ llm_config_loader.py       # é…ç½®åŠ è½½å™¨å’ŒéªŒè¯å™¨
â”œâ”€â”€ llm_config_cli.py          # å‘½ä»¤è¡Œç®¡ç†å·¥å…·
â”œâ”€â”€ llm_usage_example.py       # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ api_config.py              # ç»Ÿä¸€APIé…ç½®æ¥å£ï¼ˆå·²æ›´æ–°ï¼‰
â”œâ”€â”€ .env.llm.template          # ç¯å¢ƒå˜é‡æ¨¡æ¿
â””â”€â”€ README_LLM_CONFIG.md       # æœ¬æ–‡æ¡£
```

## ğŸ›  å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿å¹¶é…ç½®APIå¯†é’¥ï¼š

```bash
cp config/.env.llm.template config/.env.llm
# ç¼–è¾‘ .env.llm æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„APIå¯†é’¥
```

æˆ–è€…ç›´æ¥è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ï¼š

```bash
export QWEN_API_KEY="your_qwen_api_key"
export GEMINI_API_KEY="your_gemini_api_key"
export OPENAI_API_KEY="your_openai_api_key"
# ... å…¶ä»–æä¾›å•†
```

### 2. åŸºæœ¬ä½¿ç”¨

```python
from config.api_config import (
    get_api_key,
    get_enabled_llm_providers,
    get_primary_llm_provider
)

# è·å–APIå¯†é’¥ï¼ˆè‡ªåŠ¨ä»æ–°é…ç½®ç³»ç»Ÿæˆ–ä¼ ç»Ÿé…ç½®è·å–ï¼‰
qwen_key = get_api_key('qwen')
gemini_key = get_api_key('gemini')

# è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨
enabled_providers = get_enabled_llm_providers()
print(f"å¯ç”¨æä¾›å•†: {enabled_providers}")

# è·å–ä¸»è¦ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰æä¾›å•†
primary_provider = get_primary_llm_provider()
print(f"ä¸»è¦æä¾›å•†: {primary_provider}")
```

### 3. é«˜çº§ä½¿ç”¨

```python
from config.llm_config_loader import LLMConfigLoader

# åˆ›å»ºé…ç½®åŠ è½½å™¨
loader = LLMConfigLoader()
loader.load_all_configs()

# éªŒè¯æ‰€æœ‰é…ç½®
validation_results = loader.validate_all_configs()
for provider, result in validation_results.items():
    if result['valid']:
        print(f"âœ“ {provider}: é…ç½®æœ‰æ•ˆ")
    else:
        print(f"âœ— {provider}: {result.get('error', 'é…ç½®æ— æ•ˆ')}")

# æŒ‰ä¼˜å…ˆçº§è·å–é…ç½®
sorted_configs = loader.api_manager.get_configs_by_priority()
for config in sorted_configs:
    print(f"{config.provider}: ä¼˜å…ˆçº§ {config.priority}")
```

## ğŸ”§ å‘½ä»¤è¡Œå·¥å…·

ç³»ç»Ÿæä¾›äº†å¼ºå¤§çš„CLIå·¥å…·è¿›è¡Œé…ç½®ç®¡ç†ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰æä¾›å•†çŠ¶æ€
python config/llm_config_cli.py list

# æ˜¾ç¤ºè¯¦ç»†é…ç½®
python config/llm_config_cli.py show

# å¯ç”¨/ç¦ç”¨æä¾›å•†
python config/llm_config_cli.py enable qwen
python config/llm_config_cli.py disable openai

# è®¾ç½®APIå¯†é’¥
python config/llm_config_cli.py set-key qwen your_api_key_here

# è®¾ç½®ä¼˜å…ˆçº§
python config/llm_config_cli.py set-priority qwen 1

# æµ‹è¯•è¿æ¥
python config/llm_config_cli.py test qwen
python config/llm_config_cli.py test-all

# å¯¼å‡ºé…ç½®
python config/llm_config_cli.py export config_backup.yaml

# åˆ›å»ºç¯å¢ƒå˜é‡æ¨¡æ¿
python config/llm_config_cli.py create-env-template
```

## ğŸ“‹ æ”¯æŒçš„æä¾›å•†

| æä¾›å•† | æ ‡è¯†ç¬¦ | é»˜è®¤æ¨¡å‹ | çŠ¶æ€ |
|--------|--------|----------|------|
| é€šä¹‰åƒé—® | `qwen` | `qwen-turbo` | âœ… æ”¯æŒ |
| Google Gemini | `gemini` | `gemini-2.0-flash-exp` | âœ… æ”¯æŒ |
| OpenAI | `openai` | `gpt-4` | âœ… æ”¯æŒ |
| Claude | `claude` | `claude-3-sonnet-20240229` | âœ… æ”¯æŒ |
| ç™¾åº¦æ–‡å¿ƒ | `baidu` | `ernie-bot-turbo` | âœ… æ”¯æŒ |
| æ™ºè°±AI | `zhipu` | `glm-4` | âœ… æ”¯æŒ |

## âš™ï¸ é…ç½®é€‰é¡¹

æ¯ä¸ªæä¾›å•†æ”¯æŒä»¥ä¸‹é…ç½®é€‰é¡¹ï¼š

```python
@dataclass
class LLMAPIConfig:
    provider: str              # æä¾›å•†æ ‡è¯†ç¬¦
    api_key: str = ""         # APIå¯†é’¥
    api_url: str = ""         # APIç«¯ç‚¹URL
    models: List[str] = None  # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    default_model: str = ""   # é»˜è®¤æ¨¡å‹
    enabled: bool = True      # æ˜¯å¦å¯ç”¨
    priority: int = 5         # ä¼˜å…ˆçº§ï¼ˆ1-10ï¼Œ1æœ€é«˜ï¼‰
    timeout: int = 30         # è¯·æ±‚è¶…æ—¶æ—¶é—´
    max_retries: int = 3      # æœ€å¤§é‡è¯•æ¬¡æ•°
    rate_limit: int = 60      # é€Ÿç‡é™åˆ¶ï¼ˆè¯·æ±‚/åˆ†é’Ÿï¼‰
```

## ğŸ”„ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

æ–°çš„LLMé…ç½®ç³»ç»Ÿä¸ç°æœ‰çš„`api_config.py`å®Œå…¨å…¼å®¹ï¼š

```python
# ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹ï¼Œè‡ªåŠ¨ä½¿ç”¨æ–°é…ç½®ç³»ç»Ÿ
from config.api_config import get_api_key

# è¿™ä¼šä¼˜å…ˆä»æ–°é…ç½®ç³»ç»Ÿè·å–ï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ°ä¼ ç»Ÿé…ç½®
api_key = get_api_key('qwen')
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: å¤šæ¨¡å‹è´Ÿè½½å‡è¡¡

```python
from config.api_config import get_enabled_llm_providers
import random

# éšæœºé€‰æ‹©ä¸€ä¸ªå¯ç”¨çš„æä¾›å•†
available_providers = get_enabled_llm_providers()
if available_providers:
    selected_provider = random.choice(available_providers)
    api_key = get_api_key(selected_provider)
    # ä½¿ç”¨é€‰å®šçš„æä¾›å•†è¿›è¡ŒAPIè°ƒç”¨
```

### åœºæ™¯2: æ•…éšœè½¬ç§»

```python
from config.llm_config_loader import LLMConfigLoader

loader = LLMConfigLoader()
loader.load_all_configs()

# æŒ‰ä¼˜å…ˆçº§å°è¯•æä¾›å•†
configs = loader.api_manager.get_configs_by_priority()
for config in configs:
    if config.enabled and config.api_key:
        try:
            # å°è¯•ä½¿ç”¨å½“å‰æä¾›å•†
            result = call_llm_api(config)
            break
        except Exception as e:
            print(f"æä¾›å•† {config.provider} å¤±è´¥: {e}")
            continue
```

### åœºæ™¯3: æˆæœ¬ä¼˜åŒ–

```python
# æ ¹æ®æˆæœ¬é€‰æ‹©æä¾›å•†
cost_priority = {
    'qwen': 1,     # æœ€ä¾¿å®œ
    'baidu': 2,
    'zhipu': 3,
    'gemini': 4,
    'claude': 5,
    'openai': 6    # æœ€è´µ
}

available = get_enabled_llm_providers()
cheapest = min(available, key=lambda x: cost_priority.get(x, 999))
api_key = get_api_key(cheapest)
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å¯¼å…¥é”™è¯¯**: ç¡®ä¿æ‰€æœ‰ä¾èµ–æ–‡ä»¶éƒ½åœ¨æ­£ç¡®ä½ç½®
2. **APIå¯†é’¥æ— æ•ˆ**: ä½¿ç”¨CLIå·¥å…·æµ‹è¯•è¿æ¥
3. **é…ç½®ä¸ç”Ÿæ•ˆ**: æ£€æŸ¥ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶è·¯å¾„
4. **SSLè¯ä¹¦é”™è¯¯**: æŸäº›æä¾›å•†å¯èƒ½éœ€è¦ç‰¹æ®Šçš„SSLé…ç½®

### è°ƒè¯•å‘½ä»¤

```bash
# è¿è¡Œä½¿ç”¨ç¤ºä¾‹æŸ¥çœ‹è¯¦ç»†çŠ¶æ€
python config/llm_usage_example.py

# æµ‹è¯•æ‰€æœ‰æä¾›å•†è¿æ¥
python config/llm_config_cli.py test-all

# æ˜¾ç¤ºè¯¦ç»†é…ç½®ä¿¡æ¯
python config/llm_config_cli.py show
```

## ğŸ”® æœªæ¥è®¡åˆ’

- [ ] æ”¯æŒæ›´å¤šLLMæä¾›å•†
- [ ] æ·»åŠ ä½¿ç”¨ç»Ÿè®¡å’Œç›‘æ§
- [ ] å®ç°æ™ºèƒ½è·¯ç”±å’Œè´Ÿè½½å‡è¡¡
- [ ] æ”¯æŒæ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] æ·»åŠ é…ç½®çƒ­é‡è½½åŠŸèƒ½
- [ ] é›†æˆæˆæœ¬è·Ÿè¸ªå’Œé¢„ç®—æ§åˆ¶

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-12-19)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- æ”¯æŒ6ä¸ªä¸»æµLLMæä¾›å•†
- æä¾›CLIç®¡ç†å·¥å…·
- å®Œæ•´çš„é…ç½®éªŒè¯å’Œæµ‹è¯•åŠŸèƒ½
- ä¸ç°æœ‰ç³»ç»Ÿçš„æ— ç¼é›†æˆ

---

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿæˆ–æäº¤Issueã€‚